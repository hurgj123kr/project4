{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled14.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A8yL7iP1hlx"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YNdHlyQ2KHn"
      },
      "source": [
        "#베이스 모델과는 다른 방식으로 훈련데이터 테스트 데이터로 나누어준후 전처리 진행함\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyW0IYe12Wq9"
      },
      "source": [
        "from glob import glob\n",
        "path = '/content/drive/MyDrive/animals'\n",
        "dog = sorted(glob(path+'/dog' + '/*'))\n",
        "lion = sorted(glob(path+'/lion' + '/*'))\n",
        "print('dog 이미지 개수: {}\\nlion 이미지 개수: {}'.format(len(dog), len(lion)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIX8psSk2-2S"
      },
      "source": [
        "import math\n",
        "\n",
        "#비율이 적을 test먼저 분할 진행\n",
        "\n",
        "dog_test= round(len(dog)*0.2)\n",
        "lion_test = round(len(lion)*0.2)\n",
        "\n",
        "print('dog test파일에 들어갈 이미지 개수 : {}/{}'.format(dog_test,len(dog)))\n",
        "print('lion test파일에 들어갈 이미지 개수 : {}/{}'.format(lion_test,len(lion)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ1scG-p3tA9"
      },
      "source": [
        "import shutil\n",
        "import random\n",
        "def split(img_list, test_count, train_path, test_path):\n",
        "    \n",
        "    test_files=[]\n",
        "    for i in random.sample( img_list, test_count):\n",
        "        test_files.append(i)\n",
        "    \n",
        "    # 차집합방법으로 train/test 리스트 생성하기\n",
        "    train_files = [x for x in img_list if x not in test_files]\n",
        "\n",
        "    for k in train_files:\n",
        "        shutil.copy(k, train_path)\n",
        "    \n",
        "    for c in test_files:\n",
        "        shutil.copy(c, test_path)\n",
        "    \n",
        "    print('train 폴더 이미지 개수 : {}\\ntest 폴더 이미지 개수: {}'.format(len(glob(train_path+'/*')),len(glob(test_path+'/*'))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIkJ9eIq49RQ"
      },
      "source": [
        "#개와 사자 파일\n",
        "dog_train_path = '/content/drive/MyDrive/train/dog'\n",
        "dog_test_path = '/content/drive/MyDrive/test/dog' \n",
        "\n",
        "lion_train_path = '/content/drive/MyDrive/train/lion'\n",
        "lion_test_path = '/content/drive/MyDrive/test/lion'\n",
        "\n",
        "#분할\n",
        "split(dog, dog_test, dog_train_path, dog_test_path)\n",
        "split(lion, lion_test, lion_train_path,lion_test_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psfp1i798WdS"
      },
      "source": [
        "## train/test로 분할을 한 이미지들은 랜덤으로 추출했기때문에 다시 000부터 넘버링해줌."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5eeIn699Hz1"
      },
      "source": [
        "import os\n",
        "def rename(files):\n",
        "\n",
        "  if 'dog' in files[0]:\n",
        "     for i,f in enumerate(files):\n",
        "         os.rename(f, os.path.join(path+\"/dog\", 'dog_' + '{0:03d}.jpg'.format(i)))\n",
        "     dog = glob(path+\"/dog\" + '/*')    \n",
        "     print(\"dog {}번째 이미지까지 성공\".format(i+1))\n",
        "\n",
        "  elif 'lion' in files[0]:\n",
        "     for i,f in enumerate(files):\n",
        "         os.rename(f, os.path.join(path+\"/lion\", 'lion_' + '{0:03d}.jpg'.format(i)))\n",
        "     lion = glob(path+\"/lion\"+'/*')\n",
        "     print(\"lion {}번째 이미지까지 성공\".format(i+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQlAT5V8pEd"
      },
      "source": [
        "#먼저 훈련데이터 해줌.\n",
        "\n",
        "path = '/content/drive/MyDrive/train'\n",
        "dog = glob(path+'/dog'+'/*')\n",
        "lion = glob(path+'/lion'+'/*')\n",
        "\n",
        "rename(dog)\n",
        "rename(lion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxGPdv2s9_LT"
      },
      "source": [
        "path = '/content/drive/MyDrive/train'\n",
        "dog = glob(path+'/dog'+'/*')\n",
        "lion = glob(path+'/lion'+'/*')\n",
        "\n",
        "print('각각 마지막 파일 이름 : ',os.path.basename(sorted(dog)[-1]), os.path.basename(sorted(lion)[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iiutjj17-S32"
      },
      "source": [
        "#test파일 넘버링\n",
        "\n",
        "path = '/content/drive/MyDrive/test'\n",
        "dog = glob(path+'/dog'+'/*')\n",
        "lion = glob(path+'/lion'+'/*')\n",
        "\n",
        "rename(dog)\n",
        "rename(lion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t5P6RHP-tqS"
      },
      "source": [
        "path = '/content/drive/MyDrive/test'\n",
        "dog = glob(path+'/dog'+'/*')\n",
        "lion = glob(path+'/lion'+'/*')\n",
        "\n",
        "print('각각 마지막 파일 이름 : ',os.path.basename(sorted(dog)[-1]), os.path.basename(sorted(lion)[-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVOLqGii3Czc"
      },
      "source": [
        "#경로 지정\n",
        "train_path='/content/drive/MyDrive/train'\n",
        "test_path ='/content/drive/MyDrive/test'\n",
        "dog ='/dog/'\n",
        "lion = '/lion/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqDT4dfFx1tz"
      },
      "source": [
        "#이걸 실행하는것은 이것떄문에 클래스가 3개로 인식이되어짐.\n",
        "#rmdir /content/drive/MyDrive/train/.ipynb_checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Rg5AByyMFD"
      },
      "source": [
        "#rmdir /content/drive/MyDrive/test/.ipynb_checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSQH5Eb9vRwd"
      },
      "source": [
        "import tensorflow as tf\n",
        "class_names=['dog','lion']\n",
        "resize_train= tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_path,\n",
        "    class_names=class_names,\n",
        "    color_mode=\"rgb\",\n",
        "    image_size=(128, 128)\n",
        ")\n",
        "resize_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_path,\n",
        "    class_names=class_names,\n",
        "    color_mode=\"rgb\",\n",
        "    image_size = (128,128)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3pMiGRZvzjd"
      },
      "source": [
        "class_names = resize_train.class_names\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JlpDC_2zCyC"
      },
      "source": [
        "for image_batch  in resize_train:\n",
        "    print(image_batch[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGFwXNHHz_0m"
      },
      "source": [
        "#이미지 성능 향상을 위해서 사용하는것입니다.\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_dataset = resize_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = resize_test.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "#데이터셋 객체에 캐싱이나 셔플 프리배치와 같은 이미지 입력 관련 성능 향상해준다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R1KJ8wKaoA6"
      },
      "source": [
        "#시각화 진행\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy \n",
        "for images, labels in train_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i+1 )\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IkNOYp4beqi"
      },
      "source": [
        "## 데이터 전처리 진행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX3TwLafbVoN"
      },
      "source": [
        "#데이터 증강을 레이어로 만들어서 나중에 모델에 추가할 예정입니다.\n",
        "#각 순전파마다 자동으로 데이터가 증강이되며, 매번 학습이 될때마다 다른 이미지로 학습 하는 결과를 출력.\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6Y7naZucpRt"
      },
      "source": [
        "#증강된 이미지 시각화로 확인\n",
        "for image, _ in train_dataset.take(1):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    first_image = image[0]\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i+1)\n",
        "        augmented_image = data_augmentation(tf.expand_dims(first_image, 0 ))\n",
        "        plt.imshow(augmented_image[0] / 255) #normalization도 진행\n",
        "        plt.axis('off')\n",
        "#출력될때마다 다른 이미지 9개를 출력하는걸 알수있음."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeeceiCsdpQA"
      },
      "source": [
        "#이미지 사이즈를 0~255,0~1로 할지 정하기\n",
        "preprocess_input = tf.keras.layers.experimental.preprocessing.Rescaling(scale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2jJIcTPd7rn"
      },
      "source": [
        "#이미지 인식을 위해 특징을 추출하는 모델을 사용합니다.\n",
        "import tensorflow_hub as hub\n",
        "feature_extractor_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
        "IMG_SIZE = (128,128)\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "#새로운 모델을 만듭니다.\n",
        "first_model = hub.KerasLayer(feature_extractor_url, input_shape=IMG_SHAPE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJWJUg7ihXD3"
      },
      "source": [
        "#출력값 확인\n",
        "image_batch, label_batch = next(iter(train_dataset))\n",
        "feature_batch = first_model(image_batch)\n",
        "print(feature_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjw6sU3QErSb"
      },
      "source": [
        "first_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y0rELMoE8ah"
      },
      "source": [
        "##모델 조립"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhq3QyBeE-sL"
      },
      "source": [
        "#특징 추출에서 나온것을 받아보기위해서 몇개의 클래스를 반환하는 fc레이어를 제작합니다.\n",
        "prediction_layer = tf.keras.layers.Dense(len(class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaVfp8U-FuA7"
      },
      "source": [
        "inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = first_model(x, training=False)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model= tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpXgK6h8Gjt_"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpC68G2iGn0m"
      },
      "source": [
        "#모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MHoRMukG9O9"
      },
      "source": [
        "#학습 진행\n",
        "initial_epochs = 10\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data = test_dataset,\n",
        "    epochs= initial_epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBD_gGDOHglQ"
      },
      "source": [
        "#시각화 진행\n",
        "accuracy = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entorpy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXy2B_TALtp9"
      },
      "source": [
        "### 학습할 시간이 부족해서 적게 학습을 진행하였지만 학습을 할수록 모델의 성능이 좋아지고 있는걸 시각화를 통해서 확인했으며,\n",
        "- 모델의 성능이 괜찮게 나오는걸 확인을 할수있었습니다.\n",
        "- 2개의 클래스를 통해서 이미지 분류가 확실히 잘되었으므로\n",
        "- 이미지 인식을 하는 서비스를 진행할것입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBwFfxUJMG0c"
      },
      "source": [
        "## 그전에 파인 튜닝을 해서 모델을 학습 시켜서 시각화를 진행하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzvPIH3AMQpv"
      },
      "source": [
        "#파인튜닝을 했을때\n",
        "first_model.trainable = True\n",
        "\n",
        "fine_tune_epochs =10\n",
        "total_epochs = initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(train_dataset,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=test_dataset\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I718BkfN_bS"
      },
      "source": [
        "accuracy  += history_fine.history['accuracy']\n",
        "val_acc += history_fine.history['val_accuracy']\n",
        "\n",
        "loss += history_fine.history['loss']\n",
        "val_loss += history_fine.history['val_loss']\n",
        "\n",
        "#파인튜닝을 했을때 모델의 결과 시각화\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(accuracy, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.ylim([0.8, 1])\n",
        "plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.ylim([0, 1.0])\n",
        "plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4wQN5bdeOY1"
      },
      "source": [
        "#만든 모델 저장하기\n",
        "from tensorflow.python.keras.models import load_model\n",
        "model.save('mnist_mlp_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqIM9eB3UXCd"
      },
      "source": [
        "## 이미지데이터의 증강을 통해서 모델의 성능이 좋아졌지만\n",
        "### 파인튜닝을 통해서 더좋은 성능을 보여주고있는모습입니다.\n",
        "\n"
      ]
    }
  ]
}